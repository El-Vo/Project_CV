{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176541cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using YOLO world for Open Vocabulary Detection\n",
    "from ultralytics import YOLOWorld\n",
    "\n",
    "# Initialize a YOLO-World model\n",
    "model = YOLOWorld(\"yolov8s-world.pt\")  # or select yolov8m/l-world.pt for different sizes\n",
    "\n",
    "# Define desired objects/classes\n",
    "desired_object= \"red candle\"\n",
    "model.set_classes([desired_object])\n",
    "\n",
    "# Define img path and predict/show result\n",
    "img_path=\"Test_images/table.JPG\"\n",
    "results = model.predict(img_path)\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9a98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Object Tracking YOLO World\n",
    "from ultralytics import YOLOWorld\n",
    "\n",
    "model.set_classes([\"wine bottle\"])\n",
    "\n",
    "results = model.track(source=\"Test_images/video_wine_bottle.mp4\", show=True, tracker=\"bytetrack.yaml\",save=True)\n",
    "\n",
    "for result in results:\n",
    "    if result.boxes.id is not None:\n",
    "        ids = result.boxes.id.int().cpu().tolist()\n",
    "        print(f\"Tracking IDs in this frame: {ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Grounding Dino\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\n",
    "from accelerate import Accelerator\n",
    "model_id = \"IDEA-Research/grounding-dino-tiny\"\n",
    "device = Accelerator().device\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id).to(device)\n",
    "\n",
    "image_path = \"Test_images/table.JPG\"\n",
    "image = Image.open(image_path)\n",
    "# Check for cats and remote controls\n",
    "text_labels = [[\"a remote control\", \"red candle\", \"wine bottle\",\"a pair of wool socks\", \"notebook\"]]\n",
    "\n",
    "inputs = processor(images=image, text=text_labels, return_tensors=\"pt\").to(model.device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "results = processor.post_process_grounded_object_detection(\n",
    "    outputs,\n",
    "    inputs.input_ids,\n",
    "    threshold=0.3,\n",
    "    text_threshold=0.3,\n",
    "    target_sizes=[image.size[::-1]]\n",
    ")\n",
    "\n",
    "result = results[0]\n",
    "for box, score, labels in zip(result[\"boxes\"], result[\"scores\"], result[\"labels\"]):\n",
    "    box = [round(x, 2) for x in box.tolist()]\n",
    "    print(f\"Detected {labels} with confidence {round(score.item(), 3)} at location {box}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "ax.imshow(image)\n",
    "for box, score, label in zip(result[\"boxes\"], result[\"scores\"], result[\"labels\"]):\n",
    "    xmin, ymin, xmax, ymax = box.tolist()\n",
    "\n",
    "    rect = patches.Rectangle(\n",
    "        (xmin, ymin), xmax - xmin, ymax - ymin, \n",
    "        linewidth=2, edgecolor='r', facecolor='none'\n",
    "    )\n",
    "\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    plt.text(xmin, ymin - 5, f\"{label}: {score:.2f}\", \n",
    "             color='white', fontsize=12, fontweight='bold',\n",
    "             bbox=dict(facecolor='red', alpha=0.5))\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
